{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Guided Project: Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project seeks to explore data sourced from a technology space forum with the aim of determining what type of comments gain the most engagements, and at what times are they most interacted with.\n",
    "\n",
    "Hacker News is a social news website run by startup incubator; Y combinator providing ongoing news on technology and computer science related information, quite similar to Reddit; one of the most popular online user forums.\n",
    "\n",
    "**Question: What type of posts on the hacker news forum receives the most engagements?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Opening and Exploring the Hacker News DataSets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open(\"hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "#hn connotes hacker news\n",
    "\n",
    "#Displaying the first five rows to get an idea of the kind of data we're dealing with\n",
    "print(hn[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Out the Header Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "#The first row displays the header, hence we need to store it separately \n",
    "# and delete from the hn list of lists. \n",
    "\n",
    "headers = hn[0]\n",
    "\n",
    "del hn[0]\n",
    "\n",
    "print(headers)\n",
    "\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n"
     ]
    }
   ],
   "source": [
    "# Create three lists to accomodate \"ask posts\", \"show posts\" and \"others\", as the start of your filtering process.\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#The block of code below iterates throught the dataset and checks if the title indicates an \"ask\", a \"show\" or another category of posts.\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "#Reveals the number of each of the seperate categories of posts.\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "\n",
    "print(ask_posts[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments on ask posts: 14.038417431192661\n",
      "Average comments on show posts: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "#Next step in this analysis would be to determine if ask posts or show posts receive more comments on average.\n",
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(\"Average comments on ask posts: \" + str(avg_ask_comments))\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(\"Average comments on show posts: \" + str(avg_show_comments))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis, it is shown that ask posts receive more user comments on average than show posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Working to discover the number of Ask Posts and Comments by Hour Created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "# For this part of the analysis, we shall import the datetime module to parse dates stored as strings and return clear datetime objects to work with.\n",
    "import datetime as dt\n",
    "\n",
    "#A list of lists is created to house the date/time ask posts were created and the number of comments at that period.\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    empty_list = []\n",
    "    empty_list.append(row[6])\n",
    "    empty_list.append(int(row[4]))\n",
    "    result_list.append(empty_list)\n",
    "                   \n",
    "        \n",
    "#This next part of the analysis involves creating frequency tables to house the frequency of unique counts(times) and comments per those times.\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "                      \n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    dt_object = dt.datetime.strptime(date, date_format )\n",
    "    dt_hour = dt.datetime.strftime(dt_object, \"%H\")\n",
    "    if dt_hour not in counts_by_hour:\n",
    "        counts_by_hour[dt_hour] = 1\n",
    "        comments_by_hour[dt_hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[dt_hour] += 1\n",
    "        comments_by_hour[dt_hour] += row[1]\n",
    "    \n",
    "print(comments_by_hour)\n",
    "                      \n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN Posts by Hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next up would be to calculate the average amount of comments created in each unique hour extracted above; for Ask Hn Posts.\n",
    "avg_by_hour = []\n",
    "\n",
    "for key in comments_by_hour:\n",
    "        variable =  comments_by_hour[key]/counts_by_hour[key]\n",
    "        avg_by_hour.append([key, variable])\n",
    "        \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the Average Values by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n",
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [13.20183486238532, '18'], [11.46, '17'], [11.383333333333333, '01'], [11.051724137931034, '11'], [10.8, '19'], [10.25, '08'], [10.08695652173913, '05'], [9.41095890410959, '12'], [9.022727272727273, '06'], [8.127272727272727, '00'], [7.985294117647059, '23'], [7.852941176470588, '07'], [7.796296296296297, '03'], [7.170212765957447, '04'], [6.746478873239437, '22'], [5.5777777777777775, '09']]\n"
     ]
    }
   ],
   "source": [
    "#Sorting the average number of comments per hour to identify the hours with the highest values.\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    my_list = []\n",
    "    my_list.append(row[1])\n",
    "    my_list.append(row[0])\n",
    "    swap_avg_by_hour.append(my_list)\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "#Using the sort function to arrange the above list in descending order to obtain the highest.\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print(sorted_swap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask Posts Comments: \n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 hours for Ask Posts Comments: \")\n",
    "for comment_avg, hour in sorted_swap[:5]:\n",
    "    time_format = \"%H\"\n",
    "    dt_object = dt.datetime.strptime(hour,time_format).strftime(\"%H:%M\")\n",
    "    print(\"{}: {:.2f} average comments per post.\".format(dt_object,comment_avg))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis, 15:00 (3pm) came out as the hour that receives the most comments per post on average with an average of 38.59 comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "This project seeked to determine the time period with the most user interactions i.e comments in comments with the most engagements. \n",
    "Based on our analysis, creating and putting out a post between the hours of 15:00 (3pm) and 16:00 (4pm) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
